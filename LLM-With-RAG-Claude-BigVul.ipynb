{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install --quiet llama-indexÂ  # main llamaindex library\n",
    "\n",
    "!pip install --quiet llama-index-vector-stores-MongoDB # mongodb vector database\n",
    "\n",
    "!pip install --quiet llama-index-llms-anthropic # anthropic LLM provider\n",
    "\n",
    "!pip install --quiet llama-index-embeddings-openai # openai embedding provider\n",
    "\n",
    "!pip install --quiet beautifulsoup4\n",
    "\n",
    "!pip install --quiet pymongo pandas datasets # others\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import config\n",
    "\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = config.ANTHROPIC_API_KEY\n",
    "os.environ[\"HF_TOKEN\"] = config.HF_TOKEN\n",
    "os.environ[\"OPENAI_API_KEY\"] = config.OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.anthropic import Anthropic\n",
    "from llama_index.core import Settings\n",
    "llm = Anthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "\n",
    "embed_model = OpenAIEmbedding(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    dimensions=256,\n",
    "    embed_batch_size=10,\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = llm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# https://huggingface.co/datasets/bstee615/bigvul/viewer/default/train\n",
    "dataset = load_dataset(\"benjis/bigvul\", split=\"train\", streaming=True)\n",
    "dataset = dataset.take(4000)\n",
    "\n",
    "# Convert the dataset to a pandas dataframe\n",
    "dataset_df = pd.DataFrame(dataset)\n",
    "dataset_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from llama_index.core import Document\n",
    "from llama_index.core.schema import MetadataMode\n",
    "\n",
    "documents_json = dataset_df.to_json(orient='records')\n",
    "documents_list = json.loads(documents_json)\n",
    "\n",
    "llama_documents = []\n",
    "\n",
    "maxSize = 0\n",
    "\n",
    "for document in documents_list:\n",
    "    # Convert complex objects to JSON strings\n",
    "    for field in [\n",
    "        \"CVE ID\",\n",
    "        \"CVE Page\",\n",
    "        \"CWE ID\",\n",
    "        \"codeLink\",\n",
    "        \"commit_id\",\n",
    "        \"commit_message\",\n",
    "        \"func_after\",\n",
    "        \"func_before\",\n",
    "        \"lang\",\n",
    "        \"project\",\n",
    "        \"vul\"\n",
    "    ]:\n",
    "        document[field] = json.dumps(document[field])\n",
    "\n",
    "    # Create a Document object\n",
    "    llama_document = Document(\n",
    "        text=document[\"CVE Page\"],\n",
    "        metadata=document,\n",
    "        excluded_llm_metadata_keys=[\"CVE ID\", \"CWE ID\", \"codeLink\", \"commit_id\", \"lang\", \"project\", \"vul\"],\n",
    "        excluded_embed_metadata_keys=[\"CVE ID\", \"CWE ID\", \"codeLink\", \"commit_id\", \"lang\", \"project\", \"vul\"],\n",
    "        metadata_template=\"{key}=>{value}\",\n",
    "        text_template=\"Metadata: {metadata_str}\\n-----\\nContent: {content}\",\n",
    "    )\n",
    "\n",
    "    if len(llama_document.get_metadata_str()) < 10000:\n",
    "        llama_documents.append(llama_document)\n",
    "\n",
    "    maxSize = max(maxSize, len(llama_document.get_metadata_str()))\n",
    "\n",
    "# Observing input examples\n",
    "print(\"\\nThe LLM sees this: \\n\", llama_documents[0].get_content(metadata_mode=MetadataMode.LLM))\n",
    "print(\"\\nThe Embedding model sees this: \\n\", llama_documents[0].get_content(metadata_mode=MetadataMode.EMBED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "from llama_index.core.schema import MetadataMode\n",
    "from tqdm import tqdm\n",
    "\n",
    "base_splitter = TokenTextSplitter(chunk_size=10000, chunk_overlap=200)\n",
    "\n",
    "nodes = base_splitter.get_nodes_from_documents(llama_documents)\n",
    "\n",
    "# Progress bar\n",
    "pbar = tqdm(total=len(nodes), desc=\"Embedding Progress\", unit=\"node\")\n",
    "\n",
    "for node in nodes:\n",
    "    node_embedding = embed_model.get_text_embedding(\n",
    "        node.get_content(metadata_mode=MetadataMode.EMBED)\n",
    "    )\n",
    "    node.embedding = node_embedding\n",
    "    \n",
    "    # Update the progress bar\n",
    "    pbar.update(1)\n",
    "\n",
    "# Close the progress bar\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Embedding process completed!\")\n",
    "\n",
    "import pymongo\n",
    "\n",
    "os.environ[\"MONGO_URI\"] = config.MONGO_URI\n",
    "\n",
    "def get_mongo_client(mongo_uri):\n",
    "    \"\"\"Establish and validate connection to the MongoDB.\"\"\"\n",
    "    \n",
    "    client = pymongo.MongoClient(mongo_uri, appname=\"devrel.showcase.python\")\n",
    "\n",
    "    # Validate the connection\n",
    "    ping_result = client.admin.command('ping')\n",
    "    if ping_result.get('ok') == 1.0:\n",
    "        # Connection successful\n",
    "        print(\"Connection to MongoDB successful\")\n",
    "        return client\n",
    "    else:\n",
    "        print(\"Connection to MongoDB failed\")\n",
    "    return None\n",
    "\n",
    "\n",
    "mongo_client = get_mongo_client(config.MONGO_URI)\n",
    "\n",
    "DB_NAME = \"Claude\"\n",
    "COLLECTION_NAME = \"BigVulData\"\n",
    "\n",
    "db = mongo_client.get_database(DB_NAME)\n",
    "collection = db.get_collection(COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.mongodb import MongoDBAtlasVectorSearch\n",
    "\n",
    "vector_store = MongoDBAtlasVectorSearch(\n",
    "    mongo_client, \n",
    "    db_name=DB_NAME, \n",
    "    collection_name=COLLECTION_NAME, \n",
    "    index_name=\"vector_index\"\n",
    ")\n",
    "\n",
    "vector_store.add(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(vector_store)\n",
    "query_engine = index.as_query_engine(similarity_top_k=5, llm=llm)\n",
    "\n",
    "query_engine_tool = QueryEngineTool(\n",
    "    query_engine=query_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"knowledge_base\",\n",
    "        description=(\n",
    "            \"Provides information about Airbnb listings and reviews.\"\n",
    "            \"Use a detailed plain text question as input to the tool.\"\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    [query_engine_tool], llm=llm, verbose=True\n",
    ")\n",
    "agent = agent_worker.as_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.chat(\"\"\"\n",
    "#include <unistd.h>\n",
    "#include <stdlib.h>\n",
    "#include <stdlib.h>\n",
    "void *mymalloc(unsigned int size) { return malloc(size); }\n",
    "\n",
    "int main()\n",
    "{\n",
    "    char *buf;\n",
    "    size_t len;\n",
    "    read(0, &len, sizeof(len));\n",
    "    /* we forgot to check the maximum length */\n",
    "    /* 64-bit size_t gets truncated to 32-bit unsigned int */\n",
    "    buf = mymalloc(len);\n",
    "    read(0, buf, len);\n",
    "    return 0;\n",
    "}\n",
    "                      \n",
    "                      There is a vulnerability in this code, what is it and specify the CVE ID\n",
    "                      \"\"\")\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
